---
title: "Draft information"
subtitle: "version: draft-0.4"
date: "2019-12-01"
# bibliography: phd-bibliography/pollen-competition.bib
csl: ecology-letters.csl
output:
  bookdown::pdf_document2:
    # base_format: rticles::peerj_article
    keep_tex: yes
    number_sections: false
toc: false
geometry: 
  - textwidth=33em
  - textheight=48\baselineskip
# classoption: twocolumn
header-includes:
  - \usepackage{booktabs}
  - \usepackage{setspace}
  - \usepackage{lineno}
  - \usepackage{xr}
  - \usepackage[utf8]{inputenc}
  - \newcommand{\R}[1]{\label{#1}\linelabel{#1}}
  - \newcommand{\lr}[1]{page~\pageref{#1}, line~\lineref{#1}}
  - \externaldocument[M-]{manuscript}

---

\onehalfspacing

## Done

* Refocused the introduction
* Moved details of the taxonomic data cleaning process to supplementary materials
* Moved details of occurrence data cleaning process to supplementary materials
* Reorganised the results
* Rewrote most of the discussion
* Changed some details about how species are cleaned
* Removed species generality and the breadth of the environmental niche from the model
* Language is now centered on stress and specialisation. Mentioning bioclimatic suitability only when needed in the methods.

## To-do

* There are some unfamiliar warnings for when matching environmental variables to occurrences. I need to double-check this is all correct before submission. 
* Refine the supplementary results. 
* Fix references
* Finish manual species checks
* Quantify number of "true specialists", "true generalists" and flexible species.
* Check out Pedro Bergamo paper in Ecology Letters

## Comments

* Jason, thanks for proposing the idea of calculating the suitability of the community as a whole. I think it would be super exciting but didn't pursue that path. Mainly because that would imply downloading the occurrences for all the species we know their correct name as opposed to just those that are in more than one community as we do now. Currently, the occurrence data for the latter group is ~50GB. Expanding the group will likely mean dealing with 3-5 times as much data. This exercise creates some new technical problems â€” all solvable but challenging enough to take longer than what I want to budget for it. 

* Appart from that, I think I followed most suggestions one way or another. **Thanks!**
